# -*- coding: utf-8 -*-
"""embed_cluster.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12yAS3ja6CwCI6A9kWHHcROShTx55FN-c
"""

import pandas as pd
from gensim.models.doc2vec import Doc2Vec, TaggedDocument
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from collections import Counter
import json
import numpy as np
import mysql.connector


def get_doc2vec_vectors(df):
    documents = [TaggedDocument(words=str(row['keywords']).split(', '), tags=[str(row['id'])]) for index, row in df.iterrows()]
    model = Doc2Vec(documents, vector_size=50, window=5, min_count=1, workers=4, epochs=50)
    vectors_dict_list = [{str(row['id']): model.dv[str(row['id'])].tolist()} for index, row in df.iterrows()]
    
    model.save('model.bin')

    with open('vectors.json', 'w') as f:
        json.dump(vectors_dict_list, f)

    return vectors_dict_list

def cluster_messages(vectors, num_clusters):
    vector_array = [list(v.values())[0] for v in vectors]
    kmeans = KMeans(n_clusters=num_clusters, random_state=42)
    clusters = kmeans.fit_predict(vector_array)
    return clusters

def visualize_clusters_with_top_words(df):

    plt.figure(figsize=(10, 6))
    plt.scatter(df['id'], df['cluster'], c=df['cluster'], cmap='viridis', marker='o')
    plt.xlabel('Message ID')
    plt.ylabel('Cluster')
    plt.title('Clusters Visualization with Top Words by Frequency')

    # add annotations with top words for each cluster
    for cluster_id in df['cluster'].unique():
        cluster_df = df[df['cluster'] == cluster_id]
        all_keywords = ' '.join(cluster_df['keywords']).split(', ')
        top_words = [word for word, count in Counter(all_keywords).most_common(7)]
        annotation_text = ', '.join(top_words)

        # add annotation to the centroid of the cluster
        centroid_id = cluster_df['id'].mean()
        plt.annotate(annotation_text,
                     (centroid_id, cluster_id),
                     textcoords="offset points",
                     xytext=(0, 5),
                     ha='center',
                     fontsize=8,
                     color='black')

    plt.show()

def main():

    # sql_user = input("enter mysql username: ")
    # sql_pass = input("enter mysql password: ")

    # conn = mysql.connector.connect(
    #     host='localhost',
    #     user=sql_user,
    #     password=sql_pass
    # )

    # select_query = "SELECT keywords FROM posts;"

    # verify = pd.read_sql_query(select_query, conn)

    file_path = 'output_data.csv'  
    output_csv = 'new.csv'
    num_clusters = 10  
    clusters_to_visualize = [0,1,2,3,4,5,6,7,8,9]  

    df = pd.read_csv(file_path)
    vectors = get_doc2vec_vectors(df)
    clusters = cluster_messages(vectors, num_clusters)
    df['cluster'] = clusters
    df['doc2vec_vector'] = vectors
    df.to_csv(output_csv, index=False)
    visualize_clusters_with_top_words(df)

if __name__ == "__main__":
    main()

